# DocumentaciÃ³n Completa: API RAG HÃ­brida para Steam Games

## Tabla de Contenidos
1. [DescripciÃ³n General](#descripciÃ³n-general)
2. [Estructura del Proyecto](#estructura-del-proyecto)
3. [CÃ³mo Funciona](#cÃ³mo-funciona)
4. [Componentes Principales](#componentes-principales)
5. [Endpoints Disponibles](#endpoints-disponibles)
6. [Flujo de Datos](#flujo-de-datos)
7. [ConfiguraciÃ³n](#configuraciÃ³n)
8. [Despliegue](#despliegue)

---

## DescripciÃ³n General

**API RAG HÃ­brida Steam Games** es una API REST construida con `FastAPI` que permite hacer consultas sobre videojuegos de Steam de dos maneras:

1. **BÃºsquedas semÃ¡nticas (RAG)**: usando embeddings vectoriales y LLM para preguntas complejas
2. **BÃºsquedas SQL-like directas**: filtros por gÃ©nero, fecha, etc.

La API combina:
- **Elasticsearch**: motor de bÃºsqueda vectorial + texto
- **Sentence-Transformers**: generaciÃ³n de embeddings semÃ¡nticos (768 dimensiones)
- **OpenRouter LLM**: generaciÃ³n de respuestas contextuales
- **FastAPI**: servidor HTTP de alta performance

**Casos de uso:**
- "RecomiÃ©ndame juegos de supervivencia cooperativos" â†’ RAG (busca semÃ¡ntica + LLM)
- "Dame juegos gratis" â†’ SQL-like (filtro directo)
- "Juegos similares a Minecraft" â†’ kNN vectorial
- "Juegos de 2024" â†’ rango temporal

---

## Estructura del Proyecto

```
API-Reto-1/
â”œâ”€â”€ api_llm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                          # Entrypoint FastAPI
â”‚   â”œâ”€â”€ llm_manager.py                   # Gestor de LLM (OpenRouter)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ consulta_request.py          # Modelos Pydantic de entrada
â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â””â”€â”€ consulta_router.py           # DefiniciÃ³n de endpoints
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ elasticsearch_connector.py   # ConexiÃ³n y queries a ES
â”‚       â”œâ”€â”€ tokenizer.py                 # GeneraciÃ³n de embeddings
â”‚       â””â”€â”€ helpers.py                   # Funciones auxiliares
â”‚
â”œâ”€â”€ scripts-ingesta-datos/
â”‚   â””â”€â”€ json-a-elasticsearch.py          # Script para cargar datos en ES
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_endpoints.py                # Tests de endpoints
â”‚   â””â”€â”€ test_llm_response.py             # Tests de respuestas LLM
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ tokens_usage.json                # MÃ©tricas de uso
â”‚
â”œâ”€â”€ Dockerfile                           # ConfiguraciÃ³n Docker
â”œâ”€â”€ docker-compose.yml                   # OrquestaciÃ³n de servicios
â”œâ”€â”€ requirements.txt                     # Dependencias Python
â”œâ”€â”€ .env.example                         # Variables de entorno
â””â”€â”€ README.md                            # Este documento
```

---

## CÃ³mo Funciona

### Flujo General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Usuario        â”‚
â”‚  (Cliente HTTP) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ POST /consulta {"pregunta": "..."}
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Main (api_llm/main.py)     â”‚
â”‚  - CORS habilitado                  â”‚
â”‚  - Incluye router de consultas      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Router (consulta_router.py)             â”‚
â”‚  - Determina tipo de consulta            â”‚
â”‚  - Rutea a funciÃ³n correspondiente       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                           â”‚
    â–¼                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG Search          â”‚            â”‚ Direct Query         â”‚
â”‚ (/consulta)         â”‚            â”‚ (/juegos/gratis,     â”‚
â”‚ 1. Embed query      â”‚            â”‚  /juegos/por-genero, â”‚
â”‚ 2. kNN search ES    â”‚            â”‚  etc.)               â”‚
â”‚ 3. LLM response     â”‚            â”‚ 1. Build ES query    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ 2. Execute           â”‚
         â”‚                         â”‚ 3. Return results    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Elasticsearch       â”‚
         â”‚ (steam_games index)  â”‚
         â”‚ - Vectores (768d)    â”‚
         â”‚ - Metadata (txt)     â”‚
         â”‚ - Filtros (num)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ConstrucciÃ³n respuestaâ”‚
         â”‚ + Format JSON        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
              Cliente HTTP â—„â”€â”€â”€â”€
```

---

## Componentes Principales

### 1. **main.py** - InicializaciÃ³n FastAPI

```python
# Define la aplicaciÃ³n FastAPI
# Configura CORS para acceso desde cualquier origen
# Incluye el router de endpoints
```

**Responsabilidades:**
- Crear instancia de `FastAPI()`
- Agregar middleware CORS
- Registrar routers

---

### 2. **consulta_router.py** - DefiniciÃ³n de Endpoints

Define 5 endpoints principales:

#### **A. POST /consulta** (RAG Completo)
- **Entrada**: `{"pregunta": "..."}` (texto libre)
- **Proceso**:
  1. Genera embedding de la pregunta
  2. Busca contexto en Elasticsearch (kNN + match textual)
  3. EnvÃ­a contexto + pregunta al LLM
  4. Retorna respuesta generada
- **Salida**: Respuesta estructurada con score y modelo

#### **B. GET /juegos/gratis** (SQL-like)
- **Busca**: Juegos con `price_final = 0` o `is_free = true`
- **Retorna**: Lista de juegos gratis con metadata

#### **C. POST /juegos/parecidos-a** (BÃºsqueda SemÃ¡ntica)
- **Entrada**: Nombre de un juego
- **Proceso**: Busca similares usando kNN vectorial
- **Retorna**: Top 10 juegos similares

#### **D. GET /juegos/por-fecha** (Rango Temporal)
- **Entrada**: `fecha` (YYYY-MM-DD o YYYY)
- **Retorna**: Juegos de esa fecha/aÃ±o

#### **E. GET /juegos/por-genero** (BÃºsqueda Textual)
- **Entrada**: Nombre del gÃ©nero (AcciÃ³n, RPG, etc.)
- **Retorna**: Juegos del gÃ©nero especificado (con fuzzy matching)

---

### 3. **llm_manager.py** - Gestor de LLM

Encargado de comunicarse con OpenRouter.

**Funciones principales:**
- `obtener_respuesta_llm(pregunta, contexto, elastic_score)`:
  - Construye prompt con contexto
  - Realiza HTTP POST a OpenRouter API
  - Loguea tokens consumidos
  - Registra mÃ©tricas en `logs/tokens_usage.json`

**ConfiguraciÃ³n:**
- Modelo: `google/gemini-2.0-flash-lite-001` (configurable)
- API Key: desde `.env` (`OPENROUTER_API_KEY`)
- Rate limiting: integrado

---

### 4. **elasticsearch_connector.py** - ConexiÃ³n a ES

Gestiona todas las operaciones con Elasticsearch.

**Funciones principales:**
- `buscar_contexto_en_elasticsearch(pregunta)`:
  - Genera embedding de la pregunta
  - Ejecuta query hÃ­brida (kNN + BM25)
  - Retorna: documentos + score similitud

**ConfiguraciÃ³n:**
- URLs: desde `.env` (`ELASTIC_URLS`)
- API Key: desde `.env` (`ELASTIC_API_KEY`)
- Ãndice: `steam_games-*`

---

### 5. **tokenizer.py** - Embeddings

GeneraciÃ³n de vectores semÃ¡nticos.

**FunciÃ³n principal:**
- `generar_embedding(texto)`:
  - Usa modelo `sentence-transformers`
  - Retorna vector de 768 dimensiones
  - Cacheado para optimizar

**Modelo**: `all-MiniLM-L6-v2` (configurable, ~40MB)

---

### 6. **helpers.py** - Utilidades

Funciones auxiliares:
- Truncamiento de textos
- SanitizaciÃ³n de inputs
- Formateo de respuestas

---

### 7. **consulta_request.py** - Modelos Pydantic

Define estructura de datos esperada:

```python
class ConsultaRequest(BaseModel):
    pregunta: str = Field(..., description="Pregunta del usuario")
```

ValidaciÃ³n automÃ¡tica de tipos + documentaciÃ³n Swagger.

---

## Endpoints Disponibles

### Tabla Resumen

| MÃ©todo | Endpoint | Tipo | DescripciÃ³n |
|--------|----------|------|-------------|
| POST | `/consulta` | RAG | BÃºsqueda semÃ¡ntica + LLM |
| GET | `/juegos/gratis` | SQL-like | Juegos gratis |
| POST | `/juegos/parecidos-a` | kNN | Similares a un tÃ­tulo |
| GET | `/juegos/por-fecha` | Rango | Por fecha de lanzamiento |
| GET | `/juegos/por-genero` | Texto | Por gÃ©nero (fuzzy match) |

### Ejemplos de Uso

#### 1. BÃºsqueda RAG (SemÃ¡ntica + LLM)
```bash
curl -X POST http://localhost:8000/consulta \
  -H "Content-Type: application/json" \
  -d '{"pregunta": "RecomiÃ©ndame juegos de ciencia ficciÃ³n cooperativos baratos"}'
```

**Respuesta:**
```json
{
  "pregunta_realizada": "RecomiÃ©ndame juegos de ciencia ficciÃ³n cooperativos baratos",
  "score_similitud_elasticsearch": 0.92,
  "modelo_llm_respuesta": {
    "formato_texto_completo": "Te recomiendo... [respuesta generada por LLM]"
  }
}
```

#### 2. Juegos Gratis
```bash
curl http://localhost:8000/juegos/gratis
```

**Respuesta:**
```json
{
  "total": 15,
  "juegos_gratis": [
    {
      "titulo": "Team Fortress 2",
      "generos": ["AcciÃ³n", "Disparos"],
      "descripcion": "..."
    }
  ]
}
```

#### 3. Juegos Parecidos
```bash
curl -X POST "http://localhost:8000/juegos/parecidos-a?titulo=Minecraft"
```

#### 4. Juegos por AÃ±o
```bash
curl "http://localhost:8000/juegos/por-fecha?fecha=2023"
```

#### 5. Juegos por GÃ©nero
```bash
curl "http://localhost:8000/juegos/por-genero?genero=RPG"
```

---

## Flujo de Datos

### Paso 1: Ingesta de Datos

```
NDJSON vectorizado           Elasticsearch
(steam-games-data-vect.json) â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Index: steam_games-YYYY.MM.DD
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     json-a-es.py     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ {"id": 730,          â”‚                       Documentos:
â”‚  "name": "CS2",      â”‚                       â”œâ”€â”€ name (texto)
â”‚  "vector": [0.1...], â”‚                       â”œâ”€â”€ genres (array)
â”‚  "price": 0,         â”‚                       â”œâ”€â”€ price_final (nÃºmero)
â”‚  ...}                â”‚                       â”œâ”€â”€ vector_embedding (768d)
â”‚ ...                  â”‚                       â””â”€â”€ ...
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Paso 2: Consulta RAG

```
Usuario pregunta:
"Juegos de survival cooperativos"
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tokenizer.generar_embedding()       â”‚
â”‚ sentence-transformers               â”‚
â”‚ Entrada: "Juegos de survival..."    â”‚
â”‚ Salida: [0.123, 0.456, ...]  (768)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ES Query (HÃ­brido):                                  â”‚
â”‚ 1. KNN: {"field": "vector_embedding",                â”‚
â”‚          "query_vector": [0.123, ...],               â”‚
â”‚          "k": 5}                                     â”‚
â”‚ 2. BM25: {"match": {"description": "survival"}}      â”‚
â”‚ Resultado: Top 5 documentos similares                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ConstrucciÃ³n de Prompt:                              â”‚
â”‚ "Basado en estos juegos: [contexto]                  â”‚
â”‚  Responde: [pregunta]"                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenRouter LLM API:                                  â”‚
â”‚ POST https://openrouter.ai/api/v1/chat/completions   â”‚
â”‚ Payload: {model, messages, max_tokens...}            â”‚
â”‚ Respuesta: "Te recomiendo... [texto generado]"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JSON Response al Cliente:                            â”‚
â”‚ {                                                    â”‚
â”‚   "pregunta_realizada": "...",                       â”‚
â”‚   "score_similitud_elasticsearch": 0.92,             â”‚
â”‚   "modelo_llm_respuesta": {                          â”‚
â”‚     "formato_texto_completo": "Te recomiendo..."     â”‚
â”‚   }                                                  â”‚
â”‚ }                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ConfiguraciÃ³n

### Variables de Entorno (.env)

```bash
# OpenRouter LLM
OPENROUTER_API_KEY=sk-...
OPENROUTER_MODEL=google/gemini-2.0-flash-lite-001

# Elasticsearch
ELASTIC_URLS=http://localhost:9200
ELASTIC_API_KEY=id:password    # O vacÃ­o si auth no requerida
ELASTIC_INDEX_PREFIX=steam_games-*

# Embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Ruta de datos (si aplica)
DATASET_PATH=/app/data/steam-games-data-vect.ndjson
```

### DescripciÃ³n de Variables

| Variable | DescripciÃ³n | Obligatoria | Ejemplo |
|----------|-------------|-------------|---------|
| `OPENROUTER_API_KEY` | API Key de OpenRouter | SÃ­ | `sk-or-...` |
| `OPENROUTER_MODEL` | Modelo LLM a usar | No | `google/gemini-2.0-flash-lite-001` |
| `ELASTIC_URLS` | URLs de Elasticsearch | SÃ­ | `http://localhost:9200` |
| `ELASTIC_API_KEY` | Credenciales ES | No | `id:password` |
| `ELASTIC_INDEX_PREFIX` | PatrÃ³n de Ã­ndices | No | `steam_games-*` |
| `EMBEDDING_MODEL` | Modelo sentence-transformers | No | `all-MiniLM-L6-v2` |

---

## Despliegue

### 1. Desarrollo Local

```bash
# 1. Clonar y preparar entorno
cd /home/g6/API-Reto-1
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# 2. Configurar .env
cp .env.example .env
# â† Editar .env con tus credenciales

# 3. Iniciar Elasticsearch (si no estÃ¡ corriendo)
docker run -d --name elasticsearch -p 9200:9200 \
  -e "discovery.type=single-node" \
  docker.elastic.co/elasticsearch/elasticsearch:9.2.1

# 4. Cargar datos (si es la primera vez)
python scripts-ingesta-datos/json-a-elasticsearch.py

# 5. Ejecutar API
uvicorn api_llm.main:app --reload --host 0.0.0.0 --port 8000
```

**API disponible en**: `http://localhost:8000`
**DocumentaciÃ³n interactiva**: `http://localhost:8000/docs` (Swagger)

---

### 2. Docker Compose (Recomendado)

```bash
# Construir y levantar
docker-compose up --build -d

# Ver logs
docker-compose logs -f api-llm

# Detener
docker-compose down
```

**Notas:**
- El servicio en docker-compose solo levanta la API
- Elasticsearch debe estar corriendo por separado o agregarse al compose
- Volumen `.:/app` permite desarrollo hot-reload

---

### 3. ProducciÃ³n

Para desplegar en producciÃ³n:

1. **Remover volumen de cÃ³digo** en docker-compose.yml
2. **Agregar healthcheck**:
   ```yaml
   healthcheck:
     test: ["CMD", "curl", "-f", "http://localhost:8000/docs"]
     interval: 30s
     timeout: 10s
     retries: 3
   ```
3. **Usar usuario no-root** en Dockerfile
4. **Usar base de datos** para logs (en lugar de archivos)
5. **Configurar rate limiting** en LLM manager
6. **Habilitar HTTPS** con reverse proxy (Nginx)

---

## Flujo Completo de Ejemplo

### Escenario: Usuario busca "Juegos de horror baratos"

```
1ï¸âƒ£  ENTRADA
    POST /consulta
    {"pregunta": "Juegos de horror baratos"}

2ï¸âƒ£  TOKENIZACIÃ“N
    sentence-transformers genera embedding 768D
    â–¶ Vector: [0.234, -0.156, 0.892, ...]

3ï¸âƒ£  BÃšSQUEDA ELASTICSEARCH
    Query hÃ­brida:
    - kNN sobre vector_embedding
    - BM25 sobre descripciÃ³n (horror, barato)
    Resultado: 5 documentos relevantes
    â”œâ”€ Amnesia: The Dark Descent (similitud: 0.95)
    â”œâ”€ SOMA (similitud: 0.91)
    â”œâ”€ The Evil Within (similitud: 0.88)
    â”œâ”€ Resident Evil 4 Remake (similitud: 0.85)
    â””â”€ Dead Space Remake (similitud: 0.83)

4ï¸âƒ£  CONSTRUCCIÃ“N DE PROMPT
    "Basado en estos juegos recomendados:
    1. Amnesia: The Dark Descent - Horror psicolÃ³gico puro...
    2. SOMA - Horror existencial...
    3. [mÃ¡s documentos]
    
    El usuario pregunta: 'Juegos de horror baratos'
    
    Proporciona una recomendaciÃ³n Ãºtil considerando presupuesto,
    gÃ©nero y experiencia de los juegos."

5ï¸âƒ£  GENERACIÃ“N CON LLM
    OpenRouter (gemini-2.0-flash-lite-001)
    Respuesta: "Para juegos de horror baratos, te recomiendo:
    
    1. **Amnesia: The Dark Descent** - ClÃ¡sico del terror psicolÃ³gico,
       generalmente a menos de $10.
    
    2. **SOMA** - Narrativa profunda con horror existencial,
       frecuentemente en oferta.
    
    [mÃ¡s recomendaciones personalizadas]"

6ï¸âƒ£  RESPUESTA AL CLIENTE
    {
      "pregunta_realizada": "Juegos de horror baratos",
      "score_similitud_elasticsearch": 0.91,
      "modelo_llm_respuesta": {
        "formato_texto_completo": "Para juegos de horror baratos..."
      }
    }

7ï¸âƒ£  LOGGING
    tokens_usage.json registra:
    {
      "timestamp": "2025-12-09 14:32:15",
      "pregunta": "Juegos de horror baratos",
      "tokens_input": 245,
      "tokens_output": 512,
      "costo": 0.0034
    }
```

---

## Monitoreo y Mantenimiento

### Logs

- **API Principal**: `logs/llm_manager.log`
- **Tokens/MÃ©tricas**: `logs/tokens_usage.json`
- **Docker**: `docker-compose logs api-llm`

### Health Check

```bash
# Endpoint health (recomendado agregar)
curl http://localhost:8000/health

# Verificar Elasticsearch
curl http://localhost:9200/_cat/indices

# Contar documentos en Ã­ndice
curl http://localhost:9200/steam_games-*/_count
```

### Optimizaciones

1. **CachÃ© de embeddings**: Guardar embeddings frecuentes en Redis
2. **Batch indexing**: Procesar datos en lotes
3. **Query timeout**: Agregar timeouts a queries ES
4. **Rate limiting**: Limitar requests por IP
5. **CompresiÃ³n**: Comprimir respuestas HTTP

---

##  ContribuciÃ³n

Este proyecto forma parte del **Reto 1 - Sistema RAG para Steam Games**, basado en bÃºsqueda y recomendaciÃ³n de videojuegos.

**Repositorio**: `g6r12025steam-ai-chatbot`  
**Owner**: ai-somorrostro  
**Rama actual**: feature/revision-final-api  
**Autor**: Equipo G6  

---

## Estructura del proyecto completo (multirepositorio)

**Ãšltima actualizaciÃ³n**: Diciembre 2025  
**VersiÃ³n API**: 1.0  
**Rama**: `feature/revision-final-api`


# Para Â¡Â¡Â¡ VALIDACION !!!

- Requirements para el cambion

```python

--extra-index-url https://download.pytorch.org/whl/cpu
torch
fastapi
uvicorn[standard]
python-dotenv

# Embeddings ONNX
onnxruntime
numpy==1.26.4

# Chroma (por si quieres vector DB local)
chromadb

# Data handling
ndjson
requests
tqdm

# Elasticsearch
elasticsearch

# Testing
pytest
sentence-transformers

```

**Modificar el .env a esto**

```python
# Elasticsearch Configuration (Externo - levantado manualmente)
ELASTIC_URLS=https://localhost:9200  <----- de http --> https
ELASTIC_INDEX_PREFIX=steam_games-*
ELASTIC_PASSWORD=C0HcF=wHWtmHAnScY46f  <----- Cambiar
ELASTIC_USER=elastic   

# OpenRouter LLM Configuration
OPENROUTER_API_KEY=sk-or-v1-apikey-aqui


# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Logging
LOG_LEVEL=INFO

```

**Modificar el elasticsearch_connector**

```python
import os
import logging
import re 
from typing import Tuple
from elasticsearch import Elasticsearch
from dotenv import load_dotenv
from api_llm.utils.tokenizer import generar_embedding

load_dotenv()
logger = logging.getLogger(__name__)

# ================================
# ConfiguraciÃ³n conexiÃ³n segura con USUARIO Y CONTRASEÃ‘A
# ================================

ELASTIC_URLS = os.getenv("ELASTIC_URLS", "").split(",")
ELASTIC_INDEX_PREFIX = os.getenv("ELASTIC_INDEX_PREFIX", "steam_games-*")

# Obtener credenciales del .env
ELASTIC_USER = os.getenv("ELASTIC_USER", "elastic")
ELASTIC_PASSWORD = os.getenv("ELASTIC_PASSWORD", "changeme") # Pon un valor por defecto o dÃ©jalo vacÃ­o

if not ELASTIC_PASSWORD or ELASTIC_PASSWORD == "changeme":
    print("âš ï¸ ADVERTENCIA: Usando contraseÃ±a por defecto o vacÃ­a para Elasticsearch.")

es = Elasticsearch(
    hosts=ELASTIC_URLS,
    basic_auth=(ELASTIC_USER, ELASTIC_PASSWORD), # <--- AQUÃ ESTÃ EL CAMBIO
    verify_certs=False, 
    ssl_show_warn=False,
    request_timeout=30,
    max_retries=5,
    retry_on_timeout=True,
)

# ================================
# FunciÃ³n para seleccionar el Ã­ndice mÃ¡s nuevo
# ================================
def obtener_ultimo_indice(prefix_pattern: str) -> str:
    """
    Obtiene la lista de Ã­ndices que coinciden con el patrÃ³n (ej: steam_games-*)
    y devuelve el Ãºltimo alfabÃ©ticamente (que corresponde a la fecha mÃ¡s reciente).
    """
    try:
        indices = list(es.indices.get(index=prefix_pattern).keys())
        
        if not indices:
            return prefix_pattern

        indices_ordenados = sorted(indices)
        ultimo_indice = indices_ordenados[-1]
        
        return ultimo_indice

    except Exception as e:
        logger.error(f"Error buscando Ãºltimo Ã­ndice: {e}")
        return prefix_pattern

# ================================
# FunciÃ³n principal de bÃºsqueda
# ================================
def buscar_contexto_en_elasticsearch(pregunta: str, top_k: int = 10) -> Tuple[str, float]:
    """
    Realiza bÃºsqueda VECTORIAL PURA (texto comentado).
    Si detecta un precio, filtra numÃ©ricamente.
    Devuelve: (Contexto formateado, Score de relevancia 0.0 - 1.0)
    """
    try:
        embedding = generar_embedding(pregunta)
        
        # CÃ¡lculo dinÃ¡mico de candidatos
        candidates = max(50, top_k + 50)
        
        # Campos que queremos recuperar
        source_fields = [
            "name", "short_description", "detailed_description", 
            "genres", "price_category", "is_free", 
            "developers", "price_final", "metacritic_score"
        ]

        match_precio = re.search(r'(\d+[.,]\d{1,2}|\d+)', pregunta)
        
        query = {}

        if match_precio and any(x in pregunta.lower() for x in ['precio', 'cuesta', 'vale', 'euros', 'eur', '$']):
            try:
                precio_str = match_precio.group(1).replace(',', '.')
                precio_target = float(precio_str)
                logger.info(f"Filtro numÃ©rico activado: Buscando precio cercano a {precio_target}")

                # CORRECCIÃ“N: Usamos la estructura nativa 'knn' con 'filter'
                query = {
                    "size": top_k,
                    "_source": source_fields,
                    "knn": {
                        "field": "vector_embedding",
                        "query_vector": embedding,
                        "k": top_k,
                        "num_candidates": candidates,
                        "filter": {
                            "range": {
                                "price_final": {
                                    "gte": precio_target - 0.05, 
                                    "lte": precio_target + 0.05
                                }
                            }
                        }
                    }
                }
            except ValueError:
                pass

        if not query:
            query = {
                "size": top_k, 
                "_source": source_fields,
                "knn": {
                    "field": "vector_embedding", 
                    "query_vector": embedding,
                    "k": top_k,
                    "num_candidates": candidates,
                }
            }

        # Seleccionamos el Ã­ndice mÃ¡s reciente
        indice_objetivo = obtener_ultimo_indice(ELASTIC_INDEX_PREFIX)
        
        # Ejecutamos la bÃºsqueda
        response = es.search(index=indice_objetivo, body=query)
        hits = response.get("hits", {}).get("hits", [])

        if not hits:
            return "[INFO] No se encontrÃ³ contexto relevante.", 0.0

        # === CAPTURAR MAX SCORE ===
        max_score = hits[0].get("_score", 0.0)

        contexto_list = []

        for doc in hits:
            source = doc['_source']
            nombre = source.get('name', 'Desconocido')
            
            # Formateo del precio para el texto
            if source.get('is_free') or source.get('price_category') == "Gratis":
                precio_texto = "GRATIS"
            else:
                precio_val = source.get('price_final', 'N/A')
                precio_texto = f"{precio_val} EUR"
            
            info = (
                f"ğŸ® TÃ­tulo: {nombre}\n"
                f"ğŸ’° Precio: {precio_texto}\n"
                f"ğŸ·ï¸ GÃ©neros: {', '.join(source.get('genres', []))}\n"
                f"ğŸ“ DescripciÃ³n: {source.get('short_description', '')[:300]}..."
            )
            contexto_list.append(info)

        texto_final = "\n\n---\n\n".join(contexto_list)
        
        return texto_final, max_score

    except Exception as e:
        print(f"[ERROR DETALLADO]: {e}")
        return f"[ERROR Elasticsearch]: {str(e)}", 0.0
```

**Ejecucion de fastapi (paso final)**

```bash
uvicorn api_llm.main:app
```
